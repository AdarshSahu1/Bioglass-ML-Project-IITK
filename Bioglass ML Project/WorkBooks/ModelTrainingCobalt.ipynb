{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7846506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) SiO2: 13.791393744339153\n",
      "R-squared: 0.7373651320155366\n",
      "\n",
      "Root Mean Squared Error (RMSE) B2O3: 6.629149996155327\n",
      "R-squared: 0.9233147688255205\n",
      "\n",
      "Root Mean Squared Error (RMSE) CaO: 7.618811606641441\n",
      "R-squared: 0.46386746107246346\n",
      "\n",
      "Root Mean Squared Error (RMSE) Na2O: 1.676128276044931\n",
      "R-squared: 0.7015737605160871\n",
      "\n",
      "Root Mean Squared Error (RMSE) P2O5: 0.4815228818492572\n",
      "R-squared: 0.8881908939438073\n",
      "\n",
      "Root Mean Squared Error (RMSE) Co: 0.2750363612324741\n",
      "R-squared: 0.936298947368421\n",
      "\n",
      "Root Mean Squared Error (RMSE) CoO: 0.6173726717199548\n",
      "R-squared: 0.8023572948642658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Define the features (X) and the target variables (y)\n",
    "X = data[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'Surface area m2/g',\n",
    "          'Pore volume cm3/g', 'Pore size nm', 'VEGF']]\n",
    "y = data[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest Regressor model\n",
    "rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42, max_depth=2))\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variables for the testing set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "for i, target in enumerate(y.columns):\n",
    "    \n",
    "    print(f\"Root Mean Squared Error (RMSE) {target}: {rmse[i]}\")\n",
    "    print(f\"R-squared: {r2[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b868c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c41d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: SiO2\n",
      "Mean Squared Error: 301.00559047111113\n",
      "R-squared: 0.6161949684340273\n",
      "\n",
      "Target: B2O3\n",
      "Mean Squared Error: 208.2467586666667\n",
      "R-squared: 0.6608364435011163\n",
      "\n",
      "Target: CaO\n",
      "Mean Squared Error: 80.50190006811847\n",
      "R-squared: 0.3559210738019305\n",
      "\n",
      "Target: Na2O\n",
      "Mean Squared Error: 0.21836415\n",
      "R-squared: 0.9764724047205809\n",
      "\n",
      "Target: P2O5\n",
      "Mean Squared Error: 0.3914799399111115\n",
      "R-squared: 0.8061255311394694\n",
      "\n",
      "Target: Co\n",
      "Mean Squared Error: 0.05422592592592593\n",
      "R-squared: 0.9391835384615385\n",
      "\n",
      "Target: CoO\n",
      "Mean Squared Error: 0.19481133333333334\n",
      "R-squared: 0.9122189423065037\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\29200\\\\Downloads\\\\Dataset\\\\rf_multioutput_model.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN +SMOTE+Random Forest+\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Define the features (X) and the target variables (y)\n",
    "X = data[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', \n",
    "          'ALP 7', 'ALP 14', 'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm', 'VEGF']]\n",
    "y = data[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest Regressor model\n",
    "rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variables for the testing set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "for i, target in enumerate(y.columns):\n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Mean Squared Error: {mse[i]}\")\n",
    "    print(f\"R-squared: {r2[i]}\\n\")\n",
    "\n",
    "# Optionally, you can save the model using joblib\n",
    "joblib.dump(rf_model, r'C:\\Users\\29200\\Downloads\\Dataset\\rf_multioutput_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5dac7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: SiO2\n",
      "Root Mean Squared Error (RMSE): 17.34951268684833\n",
      "R-squared: 0.6161949684340273\n",
      "\n",
      "Target: B2O3\n",
      "Root Mean Squared Error (RMSE): 14.430757383681104\n",
      "R-squared: 0.6608364435011163\n",
      "\n",
      "Target: CaO\n",
      "Root Mean Squared Error (RMSE): 8.972285108494852\n",
      "R-squared: 0.3559210738019305\n",
      "\n",
      "Target: Na2O\n",
      "Root Mean Squared Error (RMSE): 0.46729450028862957\n",
      "R-squared: 0.9764724047205809\n",
      "\n",
      "Target: P2O5\n",
      "Root Mean Squared Error (RMSE): 0.625683578105668\n",
      "R-squared: 0.8061255311394694\n",
      "\n",
      "Target: Co\n",
      "Root Mean Squared Error (RMSE): 0.23286460857314906\n",
      "R-squared: 0.9391835384615385\n",
      "\n",
      "Target: CoO\n",
      "Root Mean Squared Error (RMSE): 0.4413743686864172\n",
      "R-squared: 0.9122189423065037\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\29200\\\\Downloads\\\\Dataset\\\\rf_multioutput_model.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Define the features (X) and the target variables (y)\n",
    "X = data[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', \n",
    "          'ALP 7', 'ALP 14', 'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm', 'VEGF']]\n",
    "y = data[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Random Forest Regressor model\n",
    "rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variables for the testing set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "\n",
    "# Print the evaluation metrics\n",
    "for i, target in enumerate(y.columns):\n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse[i]}\")\n",
    "    print(f\"R-squared: {r2[i]}\\n\")\n",
    "\n",
    "# Optionally, you can save the model using joblib\n",
    "joblib.dump(rf_model, r'C:\\Users\\29200\\Downloads\\Dataset\\rf_multioutput_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5766ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 8.4095, R² = 0.9098\n",
      "B2O3: RMSE = 7.6527, R² = 0.9046\n",
      "CaO: RMSE = 5.0457, R² = 0.7963\n",
      "Na2O: RMSE = 0.0000, R² = 1.0000\n",
      "P2O5: RMSE = 0.3224, R² = 0.9485\n",
      "Co: RMSE = 0.0000, R² = 1.0000\n",
      "CoO: RMSE = 0.0660, R² = 0.9980\n",
      "Overall Model RMSE: 3.0709\n",
      "Overall Model R² Score: 0.9368\n",
      "Cross-validated R² scores: [0.98087473 0.99027143 0.97511098 0.99762542 1.        ]\n",
      "Mean R² Score across all folds: 0.9888\n"
     ]
    }
   ],
   "source": [
    "#trying KNN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14','VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5','Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a multioutput regression model (Example: MultiOutputRegressor with KNeighborsRegressor)\n",
    "model = MultiOutputRegressor(KNeighborsRegressor(algorithm='ball_tree',n_neighbors=3, weights='distance', n_jobs=-1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321d640a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 15.8504, R² = 0.6797\n",
      "B2O3: RMSE = 14.4619, R² = 0.6594\n",
      "CaO: RMSE = 6.6722, R² = 0.6438\n",
      "Na2O: RMSE = 0.4526, R² = 0.9779\n",
      "P2O5: RMSE = 0.6393, R² = 0.7976\n",
      "Co: RMSE = 0.0002, R² = 1.0000\n",
      "CoO: RMSE = 0.3750, R² = 0.9366\n",
      "Overall Model RMSE: 5.4931\n",
      "Overall Model R² Score: 0.8136\n",
      "Cross-validated R² scores: [0.81662825 0.99169727 0.97071818 0.98223108 0.82789076]\n",
      "Mean R² Score across all folds: 0.9178\n"
     ]
    }
   ],
   "source": [
    "#trying GBM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a multioutput regression model (Example: MultiOutputRegressor with GradientBoostingRegressor)\n",
    "model = MultiOutputRegressor(GradientBoostingRegressor(n_estimators=79, learning_rate=0.1, max_depth=2, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecfbfe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 18.9756, R² = 0.5409\n",
      "B2O3: RMSE = 14.7659, R² = 0.6449\n",
      "CaO: RMSE = 9.4338, R² = 0.2880\n",
      "Na2O: RMSE = 1.5067, R² = 0.7554\n",
      "P2O5: RMSE = 0.6834, R² = 0.7687\n",
      "Co: RMSE = 0.2329, R² = 0.9392\n",
      "CoO: RMSE = 0.7938, R² = 0.7161\n",
      "Overall Model RMSE: 6.6274\n",
      "Overall Model R² Score: 0.6647\n",
      "Cross-validated R² scores: [0.67150372 0.63729589 0.70655025 0.86879263 0.85567978 0.74282938\n",
      " 0.68901699 0.74702821 0.61802336 0.82755741 0.85146913 0.69677922\n",
      " 0.79465445 0.77064079 0.66638956 0.62020325 0.82856165 0.43813837\n",
      " 0.82657135 0.82817323 0.52192853 0.849285   0.82605006 0.59181821\n",
      " 0.73104946 0.69589872 0.85894404 0.82606346 0.76459715 0.79699742\n",
      " 0.66169731 0.81782311 0.81290449 0.72589289 0.82665508 0.84758997\n",
      " 0.85237697 0.80552753 0.77704835 0.71477047 0.69272207 0.65729117\n",
      " 0.78808992 0.70950714 0.89120906 0.80874555 0.81862879 0.76841653\n",
      " 0.80009382 0.81746217]\n",
      "Mean R² Score across all folds: 0.7549\n",
      "Standard Deviation of R² Scores: 0.0939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14','VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5','Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a multioutput regression model (Example: MultiOutputRegressor with RandomForestRegressor)\n",
    "model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42, max_depth=2))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using repeated cross-validation\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "cv_scores = cross_val_score(model, X, y, cv=rkf, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation of R² Scores: {np.std(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b878c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 18.9756, R² = 0.5409\n",
      "B2O3: RMSE = 14.7659, R² = 0.6449\n",
      "CaO: RMSE = 9.4338, R² = 0.2880\n",
      "Na2O: RMSE = 1.5067, R² = 0.7554\n",
      "P2O5: RMSE = 0.6834, R² = 0.7687\n",
      "Co: RMSE = 0.2329, R² = 0.9392\n",
      "CoO: RMSE = 0.7938, R² = 0.7161\n",
      "Overall Model RMSE: 6.6274\n",
      "Overall Model R² Score: 0.6647\n",
      "Cross-validated R² scores: [0.8206323  0.86611884 0.81754246 0.75667603 0.7523736 ]\n",
      "Mean R² Score across all folds: 0.8027\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14','VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5','Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a multioutput regression model (Example: MultiOutputRegressor with RandomForestRegressor)\n",
    "model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42, max_depth=2))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d4b8cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 23.1622, R² = 0.3159\n",
      "B2O3: RMSE = 22.3232, R² = 0.1884\n",
      "CaO: RMSE = 8.1127, R² = 0.4734\n",
      "Na2O: RMSE = 2.4679, R² = 0.3438\n",
      "P2O5: RMSE = 0.1957, R² = 0.9810\n",
      "Co: RMSE = 0.5321, R² = 0.6824\n",
      "CoO: RMSE = 1.7392, R² = -0.3630\n",
      "Overall Model RMSE: 8.3619\n",
      "Overall Model R² Score: 0.3746\n",
      "Cross-validated R² scores: [0.47612861 0.56394306 0.48753335 0.54505703 0.41348569]\n",
      "Mean R² Score across all folds: 0.4972\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a multioutput regression model (Example: MultiOutputRegressor with SVR)\n",
    "model = MultiOutputRegressor(SVR(kernel='rbf', C=190, epsilon=0.1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a6c7584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 10.9015, R² = 0.8485\n",
      "B2O3: RMSE = 10.5930, R² = 0.8172\n",
      "CaO: RMSE = 6.7414, R² = 0.6364\n",
      "Na2O: RMSE = 2.7175, R² = 0.2043\n",
      "P2O5: RMSE = 0.5446, R² = 0.8531\n",
      "Co: RMSE = 0.6274, R² = 0.5585\n",
      "CoO: RMSE = 1.0918, R² = 0.4629\n",
      "Overall Model RMSE: 4.7453\n",
      "Overall Model R² Score: 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Plot feature coefficients\u001b[39;00m\n\u001b[0;32m     45\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 46\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(X\u001b[38;5;241m.\u001b[39mcolumns, model\u001b[38;5;241m.\u001b[39mcoef_)  \u001b[38;5;66;03m# Plotting coefficients\u001b[39;00m\n\u001b[0;32m     47\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoefficient Magnitude\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2439\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[0;32m   2437\u001b[0m         x, height, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, bottom\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2438\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mbar(\n\u001b[0;32m   2440\u001b[0m         x, height, width\u001b[38;5;241m=\u001b[39mwidth, bottom\u001b[38;5;241m=\u001b[39mbottom, align\u001b[38;5;241m=\u001b[39malign,\n\u001b[0;32m   2441\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1444\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1445\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1446\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2480\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2477\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(left, bottom, width, height, color, edgecolor, linewidth,\n\u001b[0;32m   2478\u001b[0m            hatch, patch_labels)\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l, b, w, h, c, e, lw, htch, lbl \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m-> 2480\u001b[0m     r \u001b[38;5;241m=\u001b[39m mpatches\u001b[38;5;241m.\u001b[39mRectangle(\n\u001b[0;32m   2481\u001b[0m         xy\u001b[38;5;241m=\u001b[39m(l, b), width\u001b[38;5;241m=\u001b[39mw, height\u001b[38;5;241m=\u001b[39mh,\n\u001b[0;32m   2482\u001b[0m         facecolor\u001b[38;5;241m=\u001b[39mc,\n\u001b[0;32m   2483\u001b[0m         edgecolor\u001b[38;5;241m=\u001b[39me,\n\u001b[0;32m   2484\u001b[0m         linewidth\u001b[38;5;241m=\u001b[39mlw,\n\u001b[0;32m   2485\u001b[0m         label\u001b[38;5;241m=\u001b[39mlbl,\n\u001b[0;32m   2486\u001b[0m         hatch\u001b[38;5;241m=\u001b[39mhtch,\n\u001b[0;32m   2487\u001b[0m         )\n\u001b[0;32m   2488\u001b[0m     r\u001b[38;5;241m.\u001b[39m_internal_update(kwargs)\n\u001b[0;32m   2489\u001b[0m     r\u001b[38;5;241m.\u001b[39mget_path()\u001b[38;5;241m.\u001b[39m_interpolation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\patches.py:714\u001b[0m, in \u001b[0;36mRectangle.__init__\u001b[1;34m(self, xy, width, height, angle, rotation_point, **kwargs)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;129m@_docstring\u001b[39m\u001b[38;5;241m.\u001b[39mdedent_interpd\n\u001b[0;32m    690\u001b[0m \u001b[38;5;129m@_api\u001b[39m\u001b[38;5;241m.\u001b[39mmake_keyword_only(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mangle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xy, width, height, angle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    692\u001b[0m              rotation_point\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    693\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;124;03m        %(Patch:kwdoc)s\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y0 \u001b[38;5;241m=\u001b[39m xy[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\patches.py:93\u001b[0m, in \u001b[0;36mPatch.__init__\u001b[1;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_fill(fill)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_linestyle(linestyle)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_linewidth(linewidth)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_antialiased(antialiased)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_hatch(hatch)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\patches.py:394\u001b[0m, in \u001b[0;36mPatch.set_linewidth\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m     w \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch.linewidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linewidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(w)\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dash_pattern \u001b[38;5;241m=\u001b[39m mlines\u001b[38;5;241m.\u001b[39m_scale_dashes(\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unscaled_dash_pattern, w)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the LassoLars model\n",
    "model = LassoLars(alpha=0.1)  # Adjust alpha as needed\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i], squared=False)  # Use squared=False for RMSE\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Plot feature coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(X.columns, model.coef_)  # Plotting coefficients\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Magnitude')\n",
    "plt.title('Feature Coefficients in LassoLars Model')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50cc0f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 10.9015, R² = 0.8485\n",
      "B2O3: RMSE = 10.5930, R² = 0.8172\n",
      "CaO: RMSE = 6.7414, R² = 0.6364\n",
      "Na2O: RMSE = 2.7175, R² = 0.2043\n",
      "P2O5: RMSE = 0.5446, R² = 0.8531\n",
      "Co: RMSE = 0.6274, R² = 0.5585\n",
      "CoO: RMSE = 1.0918, R² = 0.4629\n",
      "Overall Model RMSE: 4.7453\n",
      "Overall Model R² Score: 0.6258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the LassoLars model\n",
    "model = LassoLars(alpha=0.1)  # Adjust alpha as needed\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = mean_squared_error(y_test.iloc[:, i], y_pred[:, i], squared=False)  # Use squared=False for RMSE\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1fad9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 12.9862, R² = 0.7855\n",
      "B2O3: RMSE = 10.6692, R² = 0.8138\n",
      "CaO: RMSE = 6.5678, R² = 0.6116\n",
      "Na2O: RMSE = 2.6413, R² = 0.2515\n",
      "P2O5: RMSE = 0.5109, R² = 0.8703\n",
      "Co: RMSE = 0.7251, R² = 0.4313\n",
      "CoO: RMSE = 1.4605, R² = 0.0457\n",
      "Overall Model RMSE: 5.0801\n",
      "Overall Model R² Score: 0.5442\n"
     ]
    }
   ],
   "source": [
    "#trying LARS \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import root_mean_squared_error  # Import the root_mean_squared_error function\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.19, random_state=42)\n",
    "\n",
    "# Create the LassoLars model\n",
    "model = LassoLars(alpha=0.5, max_iter=180)  # Adjust alpha as needed\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = root_mean_squared_error(y_test.iloc[:, i], y_pred[:, i])  # Use root_mean_squared_error\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdd22d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 18.4226, R² = 0.5673\n",
      "B2O3: RMSE = 13.2558, R² = 0.7138\n",
      "CaO: RMSE = 6.2411, R² = 0.6884\n",
      "Na2O: RMSE = 2.7676, R² = 0.1747\n",
      "P2O5: RMSE = 1.1002, R² = 0.4006\n",
      "Co: RMSE = 0.9622, R² = -0.0385\n",
      "CoO: RMSE = 0.9244, R² = 0.6149\n",
      "Overall Model RMSE: 6.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset (replace with your file path)\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create separate HuberRegressor models for each target\n",
    "models = {}\n",
    "y_pred = pd.DataFrame()\n",
    "\n",
    "for target_col in y.columns:\n",
    "    model = HuberRegressor(epsilon=1.35)  # Adjust epsilon as needed\n",
    "    model.fit(X_train, y_train[target_col])\n",
    "    models[target_col] = model\n",
    "    y_pred[target_col] = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for each target separately\n",
    "overall_rmse = 0\n",
    "for column in y.columns:\n",
    "    rmse = mean_squared_error(y_test[column], y_pred[column], squared=False)\n",
    "    r2 = r2_score(y_test[column], y_pred[column])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= len(y.columns)\n",
    "\n",
    "# Overall model score (you can compute overall R^2 if needed)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b024c4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 12.0663, R² = 0.8144\n",
      "B2O3: RMSE = 12.9129, R² = 0.7284\n",
      "CaO: RMSE = 5.6817, R² = 0.7417\n",
      "Na2O: RMSE = 2.6288, R² = 0.2554\n",
      "P2O5: RMSE = 0.5680, R² = 0.8403\n",
      "Co: RMSE = 0.9623, R² = -0.0385\n",
      "CoO: RMSE = 0.9786, R² = 0.5685\n",
      "Overall Model RMSE: 5.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset (replace with your file path)\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create separate HuberRegressor models for each target\n",
    "models = {}\n",
    "y_pred = pd.DataFrame()\n",
    "\n",
    "for target_col in y.columns:\n",
    "    model = HuberRegressor(epsilon=1.35, max_iter=1000)  # Adjust max_iter as needed\n",
    "    model.fit(X_train, y_train[target_col])\n",
    "    models[target_col] = model\n",
    "    y_pred[target_col] = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for each target separately\n",
    "overall_rmse = 0\n",
    "for column in y.columns:\n",
    "    rmse = mean_squared_error(y_test[column], y_pred[column], squared=False)\n",
    "    r2 = r2_score(y_test[column], y_pred[column])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= len(y.columns)\n",
    "\n",
    "# Overall model score (you can compute overall R^2 if needed)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d5131bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 14.9731, R² = 0.7141\n",
      "B2O3: RMSE = 13.4936, R² = 0.7035\n",
      "CaO: RMSE = 5.6588, R² = 0.7438\n",
      "Na2O: RMSE = 2.7146, R² = 0.2060\n",
      "P2O5: RMSE = 0.4957, R² = 0.8783\n",
      "Co: RMSE = 0.9622, R² = -0.0385\n",
      "CoO: RMSE = 0.9867, R² = 0.5613\n",
      "Overall Model RMSE: 5.6121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset (replace with your file path)\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create separate HuberRegressor models for each target\n",
    "models = {}\n",
    "y_pred = pd.DataFrame()\n",
    "\n",
    "for target_col in y.columns:\n",
    "    model = HuberRegressor(epsilon=1.35, max_iter=1000)  # Adjust max_iter as needed\n",
    "    model.fit(X_train, y_train[target_col])\n",
    "    models[target_col] = model\n",
    "    y_pred[target_col] = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for each target separately\n",
    "overall_rmse = 0\n",
    "for column in y.columns:\n",
    "    rmse = mean_squared_error(y_test[column], y_pred[column], squared=False)\n",
    "    r2 = r2_score(y_test[column], y_pred[column])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= len(y.columns)\n",
    "\n",
    "# Overall model score (you can compute overall R^2 if needed)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70c8b96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 11.0248, R² = 0.8450\n",
      "B2O3: RMSE = 10.4797, R² = 0.8211\n",
      "CaO: RMSE = 7.6642, R² = 0.5300\n",
      "Na2O: RMSE = 2.6678, R² = 0.2332\n",
      "P2O5: RMSE = 0.5153, R² = 0.8685\n",
      "Co: RMSE = 0.6173, R² = 0.5726\n",
      "CoO: RMSE = 0.9292, R² = 0.6110\n",
      "Overall Model RMSE: 4.8426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset (replace with your file path)\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Define features (X) and targets (y)\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14', 'VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create separate BayesianRidge models for each target\n",
    "models = {}\n",
    "y_pred = pd.DataFrame()\n",
    "\n",
    "for target_col in y.columns:\n",
    "    model = BayesianRidge()\n",
    "    model.fit(X_train, y_train[target_col])\n",
    "    models[target_col] = model\n",
    "    y_pred[target_col] = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for each target separately\n",
    "overall_rmse = 0\n",
    "for column in y.columns:\n",
    "    rmse = mean_squared_error(y_test[column], y_pred[column], squared=False)\n",
    "    r2 = r2_score(y_test[column], y_pred[column])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= len(y.columns)\n",
    "\n",
    "# Overall model score (you can compute overall R^2 if needed)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2628c2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 14.6605, R² = 0.7446\n",
      "B2O3: RMSE = 12.3729, R² = 0.7404\n",
      "CaO: RMSE = 6.5571, R² = 0.6249\n",
      "Na2O: RMSE = 0.2813, R² = 0.9909\n",
      "P2O5: RMSE = 0.5681, R² = 0.8372\n",
      "Co: RMSE = 0.6794, R² = 0.6422\n",
      "CoO: RMSE = 0.3527, R² = 0.9371\n",
      "Overall Model RMSE: 5.0674\n",
      "Overall Model R² Score: 0.7882\n",
      "Cross-validated R² scores: [0.97013528 0.84109556 0.96928478 0.98390126 0.98045192]\n",
      "Mean R² Score across all folds: 0.9490\n"
     ]
    }
   ],
   "source": [
    "#trying ADAboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14','VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5','Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29, random_state=42)\n",
    "\n",
    "# Choose a multioutput regression model (Example: MultiOutputRegressor with AdaBoostRegressor)\n",
    "model = MultiOutputRegressor(AdaBoostRegressor(random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5315a860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 0.0000, R² = 1.0000\n",
      "B2O3: RMSE = 14.8602, R² = 0.6403\n",
      "CaO: RMSE = 0.0000, R² = 1.0000\n",
      "Na2O: RMSE = 0.0000, R² = 1.0000\n",
      "P2O5: RMSE = 0.3817, R² = 0.9279\n",
      "Co: RMSE = 0.0482, R² = 0.9974\n",
      "CoO: RMSE = 0.0000, R² = 1.0000\n",
      "Overall Model RMSE: 2.1843\n",
      "Overall Model R² Score: 0.9379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R² scores: [0.75167144 0.98224712 0.9041537  0.99999294 0.85714286]\n",
      "Mean R² Score across all folds: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#trying gaussian process regressor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14','VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5','Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Gaussian Process kernel\n",
    "kernel = RBF()\n",
    "\n",
    "# Choose a multioutput regression model (Example: MultiOutputRegressor with GaussianProcessRegressor)\n",
    "model = MultiOutputRegressor(GaussianProcessRegressor(kernel=kernel, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "338bf526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiO2: RMSE = 15.8078, R² = 0.6997\n",
      "B2O3: RMSE = 13.2201, R² = 0.7160\n",
      "CaO: RMSE = 2.4965, R² = 0.9507\n",
      "Na2O: RMSE = 0.0000, R² = 1.0000\n",
      "P2O5: RMSE = 0.9781, R² = 0.5320\n",
      "Co: RMSE = 1.0756, R² = 0.2103\n",
      "CoO: RMSE = 0.0000, R² = 1.0000\n",
      "Overall Model RMSE: 4.7969\n",
      "Overall Model R² Score: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated R² scores: [0.80250354 0.98384119 0.93857547 0.99992678 0.85714286]\n",
      "Mean R² Score across all folds: 0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\29200\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:445: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = r\"C:\\Users\\29200\\Downloads\\Dataset\\Co_oversampled_resampled.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming your X and y are prepared based on your specific columns\n",
    "X = df[['Conc.', 'Cell Viability 24', 'Cell Viability 48', 'Cell Viability 72', 'ALP 14','VEGF',\n",
    "        'Surface area m2/g', 'Pore volume cm3/g', 'Pore size nm']]\n",
    "y = df[['SiO2', 'B2O3', 'CaO', 'Na2O', 'P2O5', 'Co', 'CoO']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.24, random_state=42)\n",
    "\n",
    "# Define GaussianProcessRegressor with default kernel\n",
    "kernel = 1.0 * RBF(length_scale=1.0) + WhiteKernel(noise_level=1e-5)\n",
    "model = MultiOutputRegressor(GaussianProcessRegressor(kernel=kernel, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE and R² score for each output variable\n",
    "overall_rmse = 0\n",
    "for i, column in enumerate(y.columns):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "    overall_rmse += rmse\n",
    "    print(f\"{column}: RMSE = {rmse:.4f}, R² = {r2:.4f}\")\n",
    "\n",
    "# Calculate overall RMSE\n",
    "overall_rmse /= y.shape[1]\n",
    "\n",
    "# Overall model score\n",
    "overall_r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Overall Model RMSE: {overall_rmse:.4f}\")\n",
    "print(f\"Overall Model R² Score: {overall_r2:.4f}\")\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(f\"Cross-validated R² scores: {cv_scores}\")\n",
    "print(f\"Mean R² Score across all folds: {np.mean(cv_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc065b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
